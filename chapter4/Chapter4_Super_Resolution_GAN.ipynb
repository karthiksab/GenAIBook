{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPJIb56NfUqt"
      },
      "source": [
        "The idea has been derived and changed from SRGAN solution of\n",
        "https://github.com/krasserm/super-resolution/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeVj2VmGlcRb",
        "outputId": "e8502a4a-e1fd-4571-b003-a30f7eb1176a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk2bsdy7HtrJ"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z8MINDUHXpAd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # software library for high performance numerical computation\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19   #Instantiates the VGG19 architecture.\n",
        "import shutil\n",
        "from tensorflow.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, LeakyReLU, PReLU, Lambda #Basic building blocks of neural network\n",
        "from tensorflow.keras.models import Model #  A model grouping layers into an object with training/inference features.\n",
        "from tensorflow.keras.optimizers import Adam  # Importing optimizers\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError, MeanSquaredError # importing losses\n",
        "from tensorflow.keras.metrics import Mean # importing metrics\n",
        "\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt  # for image processing\n",
        "import numpy as np # for arrays and matrices\n",
        "from PIL import Image  # for image visualization\n",
        "import time\n",
        "#Python environment to draw the plots immediately after the current\n",
        "from tensorflow.python.data.experimental import AUTOTUNE # To create multiple processor threa\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay # optimizer decay\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsNFeemQK0Vh"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ye1-j0h-r_w0"
      },
      "outputs": [],
      "source": [
        "#Function for randomly cutting phrases from low-quality and high-quality images\n",
        "def crop(low_res_img, high_res_img, high_res_crop_size=96, scale=2):\n",
        "    lr_crop_size = high_res_crop_size // scale #Image crop size\n",
        "    low_res_img_shape = tf.shape(low_res_img)[:2] #low resolution cropped image shape\n",
        "    low_res_width = tf.random.uniform(shape=(), maxval=low_res_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n",
        "    low_res_height = tf.random.uniform(shape=(), maxval=low_res_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n",
        "    high_res_width = low_res_width * scale\n",
        "    high_res_height = low_res_height * scale\n",
        "    #cropping of images\n",
        "    low_res_img_cropped = low_res_img[low_res_height:low_res_height + lr_crop_size, low_res_width:low_res_width + lr_crop_size]\n",
        "    high_res_img_cropped = high_res_img[high_res_height:high_res_height + high_res_crop_size, high_res_width:high_res_width + high_res_crop_size]\n",
        "\n",
        "    return low_res_img_cropped, high_res_img_cropped\n",
        "\n",
        "def random_flip(lr_img, hr_img):\n",
        "    rn = tf.random.uniform(shape=(), maxval=1)\n",
        "    return tf.cond(rn < 0.5,\n",
        "                   lambda: (lr_img, hr_img),\n",
        "                   lambda: (tf.image.flip_left_right(lr_img),\n",
        "                            tf.image.flip_left_right(hr_img)))\n",
        "\n",
        "def random_rotate(lr_img, hr_img):\n",
        "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
        "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
        "\n",
        "\n",
        "\n",
        "#Download dataset\n",
        "def download(file, dir, extract=True):\n",
        "    url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n",
        "    tf.keras.utils.get_file(file, url, cache_subdir=os.path.abspath(dir), extract=extract)\n",
        "    os.remove(os.path.join(dir, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "code",
        "id": "a9mEqTma7BFU"
      },
      "outputs": [],
      "source": [
        "class main_dataset:\n",
        "    def __init__(self,\n",
        "                 selection='train', # selection\n",
        "                 img_dir='/content/drive/MyDrive/GenAIBOOK/SRGAN/dataset/images', # images directory\n",
        "                 cach_dir='/content/drive/MyDrive/GenAIBOOK/SRGAN/dataset/caches'): # cache directory\n",
        "\n",
        "        self.scale =  4 # scale of image reduction along each axis\n",
        "        self.downgrade = 'bicubic' #Bi-Cubic Interpolation is a powerful algorithm for image scaling,\n",
        "        self.selection = selection\n",
        "        self.img_dir = img_dir\n",
        "        self.cach_dir = cach_dir\n",
        "\n",
        "        os.makedirs(img_dir, exist_ok=True)\n",
        "        os.makedirs(cach_dir, exist_ok=True)\n",
        "\n",
        "        # Train and valid split\n",
        "        if selection == 'train':\n",
        "            self.image_ids = range(1, 801)\n",
        "        elif selection == 'valid':\n",
        "            self.image_ids = range(801, 901)\n",
        "        else:\n",
        "            raise ValueError(\"selection must be 'train' or 'valid'\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def dataset(self, batch_size=16, repeat_count=None, transform=True):\n",
        "        ds = tf.data.Dataset.zip((self.lr_dataset(), self.hr_dataset())) # dataset creation (lr,hr)\n",
        "        if transform: # image transformations\n",
        "            ds = ds.map(lambda lr, hr: crop(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE) #random cropping\n",
        "            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
        "            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
        "        ds = ds.batch(batch_size) # Combines consecutive elements of the dataset into groups\n",
        "        ds = ds.repeat(repeat_count) #repeat is used to iterate over a dataset in multiple epochs (epoch is a complete dataset).\n",
        "        ds = ds.prefetch(buffer_size=AUTOTUNE)  #prefetching one batch of data for better performance\n",
        "        return ds\n",
        "\n",
        "    #High Resolution Dataset\n",
        "    def hr_dataset(self):\n",
        "        if not os.path.exists(os.path.join(self.img_dir, f'DIV2K_{self.selection}_HR')):\n",
        "            download(f'DIV2K_{self.selection}_HR.zip', self.img_dir, extract=True)\n",
        "        ds = self.img_dataset(self.high_res_img_files()).cache(self.high_res_cach_file()) #Create dataset from photo cache\n",
        "        return ds\n",
        "\n",
        "    #low resolution dataset\n",
        "    def lr_dataset(self):\n",
        "        if not os.path.exists(os.path.join(self.img_dir, f'DIV2K_{self.selection}_LR_{self.downgrade}', f'X{self.scale}')):\n",
        "            download(f'DIV2K_{self.selection}_LR_{self.downgrade}_X{self.scale}.zip', self.img_dir, extract=True)\n",
        "        ds = self.img_dataset(self.low_res_img_files()).cache(self.low_res_cach_file()) # Create dataset from phtoto chache\n",
        "        return ds\n",
        "\n",
        "    def high_res_cach_file(self): #Image cache path for high qualilty images\n",
        "        return os.path.join(self.cach_dir, f'DIV2K_{self.selection}_HR.cache')\n",
        "\n",
        "    def low_res_cach_file(self): #Image cache path for low qualilty images\n",
        "        return os.path.join(self.cach_dir, f'DIV2K_{self.selection}_LR_{self.downgrade}_X{self.scale}.cache')\n",
        "\n",
        "    def high_res_cach_index(self): # image cache indexes\n",
        "        return f'{self.high_res_cach_file()}.index'\n",
        "\n",
        "    def low_res_cach_index(self): # image cache indexws\n",
        "        return f'{self.low_res_cach_file()}.index'\n",
        "\n",
        "    #List of high quality images\n",
        "    def high_res_img_files(self):\n",
        "        img_dir = os.path.join(self.img_dir, f'DIV2K_{self.selection}_HR')\n",
        "        return [os.path.join(img_dir, f'{image_id:04}.png') for image_id in self.image_ids]\n",
        "\n",
        "    #List of low quality images\n",
        "    def low_res_img_files(self):\n",
        "        img_dir = os.path.join(self.img_dir, f'DIV2K_{self.selection}_LR_{self.downgrade}', f'X{self.scale}')\n",
        "        return [os.path.join(img_dir, f'{image_id:04}x{self.scale}.png') for image_id in self.image_ids]\n",
        "\n",
        "    #Dataset generation\n",
        "    @staticmethod\n",
        "    def img_dataset(image_files):\n",
        "        ds = tf.data.Dataset.from_tensor_slices(image_files) # dataset conversion\n",
        "        ds = ds.map(tf.io.read_file) # read image and add to dataset\n",
        "        ds = ds.map(lambda x: tf.image.decode_png(x, channels=3), num_parallel_calls=AUTOTUNE) # convert to 3 channel images\n",
        "        return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QYTeHJK6vTNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41af447-db23-4546-fe01-cc515ceea45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
            "246914039/246914039 [==============================] - 13s 0us/step\n",
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "3530603713/3530603713 [==============================] - 179s 0us/step\n",
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip\n",
            "31505881/31505881 [==============================] - 9s 0us/step\n",
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
            "448993893/448993893 [==============================] - 34s 0us/step\n"
          ]
        }
      ],
      "source": [
        "img_train = main_dataset(selection='train')\n",
        "img_valid = main_dataset(selection='valid')\n",
        "train_ds = img_train.dataset(batch_size=16, transform=True)\n",
        "valid_ds = img_valid.dataset(batch_size=16, transform=True, repeat_count=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n70qnjIk4NgS"
      },
      "source": [
        "#Training Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RI1EENB6YgH"
      },
      "outputs": [],
      "source": [
        "# Universal class for training\n",
        "class Univ_Trainer:\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 loss,\n",
        "                 learning_rate,\n",
        "                 checkpoint_dir='/content/drive/MyDrive/GenAIBOOK/SRGAN/ckpt/edsr'):\n",
        "\n",
        "        self.now = None\n",
        "        self.loss = loss\n",
        "        #Saving checkpoint\n",
        "        self.checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
        "                                              psnr=tf.Variable(-1.0),\n",
        "                                              optimizer=Adam(learning_rate),\n",
        "                                              model=model)\n",
        "        #Checkpoint configuration\n",
        "        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint=self.checkpoint,\n",
        "                                                             directory=checkpoint_dir,\n",
        "                                                             max_to_keep=3)\n",
        "        self.restore() #Restore checkpoint\n",
        "\n",
        "    #Built-in decorator\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.checkpoint.model\n",
        "\n",
        "\n",
        "    def train(self, train_dataset, valid_dataset, steps, evaluate_every=1000):\n",
        "        loss_mean = Mean()\n",
        "\n",
        "        ckpt_mgr = self.checkpoint_manager\n",
        "        ckpt = self.checkpoint\n",
        "\n",
        "        self.now = time.perf_counter()\n",
        "\n",
        "        for lr, hr in train_dataset.take(steps - ckpt.step.numpy()):\n",
        "            ckpt.step.assign_add(1)\n",
        "            step = ckpt.step.numpy()\n",
        "\n",
        "            loss = self.train_step(lr, hr)\n",
        "            print(\"loss is calculated\")\n",
        "            loss_mean(loss)\n",
        "\n",
        "            # Disply information based on\n",
        "            if step % evaluate_every == 0:\n",
        "                #Calculate average error\n",
        "                loss_value = loss_mean.result()\n",
        "                loss_mean.reset_states()\n",
        "\n",
        "                # Calculate PSNR\n",
        "                psnr_value = self.evaluate(valid_dataset)\n",
        "                duration = time.perf_counter() - self.now\n",
        "                print(f'{step}/{steps}: loss = {loss_value.numpy():.3f}, PSNR = {psnr_value.numpy():3f} ({duration:.2f}s)')\n",
        "\n",
        "                #Save check point\n",
        "                ckpt.psnr = psnr_value\n",
        "                ckpt_mgr.save()\n",
        "                #Reset the current time\n",
        "                self.now = time.perf_counter()\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, lr, hr):\n",
        "\n",
        "        with tf.GradientTape() as tape: # Gradient descent\n",
        "\n",
        "            #casting tensors to float\n",
        "            lr = tf.cast(lr, tf.float32)\n",
        "            hr = tf.cast(hr, tf.float32)\n",
        "\n",
        "            #error\n",
        "            sr = self.checkpoint.model(lr, training=True)\n",
        "            loss_value = self.loss(hr, sr)\n",
        "\n",
        "        #Applying gradients\n",
        "        gradients = tape.gradient(loss_value, self.checkpoint.model.trainable_variables)\n",
        "        self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n",
        "\n",
        "        return loss_value\n",
        "\n",
        "    def evaluate(self, dataset):\n",
        "        return evaluate(self.checkpoint.model, dataset)\n",
        "\n",
        "    #Restore model from control point\n",
        "    def restore(self):\n",
        "        if self.checkpoint_manager.latest_checkpoint:\n",
        "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
        "            print(f'Model restored from checkpoint at step {self.checkpoint.step.numpy()}.')\n",
        "\n",
        "\n",
        "#Inherits charachterestics of trainer class\n",
        "class SrganGeneratorTrainer(Univ_Trainer):\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 checkpoint_dir,\n",
        "                 learning_rate=1e-4):\n",
        "        super().__init__(model, loss=MeanSquaredError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n",
        "\n",
        "    #Setting traing paramerters\n",
        "    def train(self, train_dataset, valid_dataset, steps=5000, evaluate_every=100):\n",
        "        super().train(train_dataset, valid_dataset, steps, evaluate_every)\n",
        "\n",
        "#Class to train the model\n",
        "\n",
        "class SrganTrainer:\n",
        "\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 discriminator,\n",
        "                 content_loss='VGG54',\n",
        "                 learning_rate=PiecewiseConstantDecay(boundaries=[1000], values=[1e-4, 1e-5])):\n",
        "        vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "        self.vgg = Model(vgg.input, vgg.layers[20].output)\n",
        "        self.content_loss = content_loss\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.optimizer_gen = Adam(learning_rate=learning_rate)\n",
        "        self.optimizer_disc = Adam(learning_rate=learning_rate)\n",
        "        self.bce_loss = BinaryCrossentropy(from_logits=False)\n",
        "        self.mse_loss = MeanSquaredError()\n",
        "\n",
        "    #Define train function\n",
        "    def train(self, train_dataset, steps=2000):\n",
        "        pls_metric = Mean() # perception error\n",
        "        dls_metric = Mean() # discriminator error\n",
        "        step = 0\n",
        "\n",
        "        for lr_img, hr_img in train_dataset.take(steps):\n",
        "            step += 1\n",
        "            pl, dl = self.train_step(lr_img, hr_img)\n",
        "            pls_metric(pl)\n",
        "            dls_metric(dl)\n",
        "\n",
        "            if step % 200 == 0: # for evey 200 steps\n",
        "                print(f'{step}/{steps}, perceptual loss = {pls_metric.result():.4f}, discriminator loss = {dls_metric.result():.4f}') #Выводим текущую информацию\n",
        "                pls_metric.reset_states()\n",
        "                dls_metric.reset_states()\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, lr_output, hr_output):\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            #cast tensor to new type\n",
        "            lr_output = tf.cast(lr_output, tf.float32)\n",
        "            hr_output = tf.cast(hr_output, tf.float32)\n",
        "\n",
        "            #Generating Super Resolution - Image\n",
        "            sr_output = self.generator(lr_output, training=True)\n",
        "\n",
        "            #send the real image to discriminator\n",
        "            hr_output_f = self.discriminator(hr_output, training=True)\n",
        "            sr_output_f = self.discriminator(sr_output, training=True)\n",
        "\n",
        "            content_loss = self._content_loss(hr_output, sr_output)\n",
        "            generator_loss = self._generator_loss(sr_output_f)\n",
        "\n",
        "            #The SRGAN uses perpetual loss function (LSR)  which is the weighted sum of two loss components\n",
        "            #1.content loss 2. adversarial loss.\n",
        "\n",
        "            perpetual_loss = content_loss + 0.001 * generator_loss\n",
        "            discriminator_loss = self._discriminator_loss(hr_output_f, sr_output_f)\n",
        "\n",
        "        #Applying gradients to genreator and discriminator\n",
        "        gradients_of_generator = gen_tape.gradient(perpetual_loss, self.generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(discriminator_loss, self.discriminator.trainable_variables)\n",
        "        self.optimizer_gen.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.optimizer_disc.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n",
        "        return perpetual_loss, discriminator_loss\n",
        "\n",
        "#The SRGAN uses perpetual loss function (LSR)  which is the weighted sum of two loss components : content loss (VGG) and adversarial loss.\n",
        "# VGG loss is based on the ReLU activation layers of the pre-trained 19 layer VGG network\n",
        "\n",
        "    # Defining content_loss\n",
        "    @tf.function\n",
        "    def _content_loss(self, hr_output, sr_output):\n",
        "        sr = preprocess_input(sr_output)\n",
        "        hr = preprocess_input(hr_output)\n",
        "        sr_features = self.vgg(sr) / 12.75\n",
        "        hr_features = self.vgg(hr) / 12.75\n",
        "        return self.mse_loss(hr_features, sr_features)\n",
        "\n",
        "    # Defining generator_loss\n",
        "    def _generator_loss(self, sr_output):\n",
        "        return self.bce_loss(tf.ones_like(sr_output), sr_output)\n",
        "\n",
        "    # Defining discriminator_loss\n",
        "    def _discriminator_loss(self, hr_output, sr_output):\n",
        "        hr_output_loss = self.bce_loss(tf.ones_like(hr_output), hr_output)\n",
        "        sr_output_loss = self.bce_loss(tf.zeros_like(sr_output), sr_output)\n",
        "        return hr_output_loss + sr_output_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUCfF-X-8aP8"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqDdxGxn6L1u"
      },
      "outputs": [],
      "source": [
        "def resolve(model, lr_batch):\n",
        "    lr_batch = tf.cast(lr_batch, tf.float32)\n",
        "    sr_batch = model(lr_batch)\n",
        "    sr_batch = tf.clip_by_value(sr_batch, 0, 255)\n",
        "    sr_batch = tf.round(sr_batch)\n",
        "    sr_batch = tf.cast(sr_batch, tf.uint8)\n",
        "    return sr_batch\n",
        "\n",
        "def evaluate(model, dataset):\n",
        "    psnr_values = []\n",
        "    for lr, hr in dataset:\n",
        "        sr = resolve(model, lr)\n",
        "        psnr_value = psnr(hr, sr)[0]\n",
        "        psnr_values.append(psnr_value)\n",
        "    return tf.reduce_mean(psnr_values)\n",
        "\n",
        "\n",
        "# Normalize RGB Images [0, 1]\n",
        "def norm01(x):\n",
        "    return x / 255.0\n",
        "\n",
        "# Normalize RGB Images [-1, 1]\n",
        "def norm11(x):\n",
        "    return x / 127.5 - 1\n",
        "\n",
        "# Denormalize the images\n",
        "def denorm11(x):\n",
        "    return (x + 1) * 127.5\n",
        "\n",
        "#Меtrics - The mean-square error (MSE) and the peak signal-to-noise ratio (PSNR)\n",
        "#are used to compare image compression quality.\n",
        "def psnr(z1, z2):\n",
        "    return tf.image.psnr(z1, z2, max_val=255)\n",
        "\n",
        "def pixel_shuffle(scale):\n",
        "    return lambda x: tf.nn.depth_to_space(x, scale) #Rearranges data from depth into blocks of spatial data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVuHe3XU6ERQ"
      },
      "outputs": [],
      "source": [
        "low_res_size = 24\n",
        "high_res_size = 96\n",
        "\n",
        "# upSmaple Block\n",
        "def up_sample(x_in, filters_num):\n",
        "    x = Conv2D(filters_num, kernel_size=3, padding='same')(x_in)\n",
        "    x = Lambda(pixel_shuffle(scale=2))(x)\n",
        "    return PReLU(shared_axes=[1, 2])(x)\n",
        "\n",
        "# res_block\n",
        "def resnet_block(x_in, filters_num, momentum=0.7):\n",
        "    x = Conv2D(filters_num, kernel_size=3, padding='same')(x_in)\n",
        "    x = BatchNormalization(momentum=momentum)(x)\n",
        "    x = PReLU(shared_axes=[1, 2])(x)\n",
        "    x = Conv2D(filters_num, kernel_size=3, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=momentum)(x)\n",
        "    x = Add()([x_in, x])\n",
        "    return x\n",
        "\n",
        "# Generator architecture\n",
        "def generator_sr_resnet(filters_num=64, num_res_blocks=16):\n",
        "    x_in = Input(shape=(None, None, 3))\n",
        "    x_g = Lambda(norm01)(x_in)\n",
        "\n",
        "    x_g = Conv2D(filters_num, kernel_size=9, padding='same')(x_g)\n",
        "    x_g = x_1 = PReLU(shared_axes=[1, 2])(x_g)\n",
        "\n",
        "    for _ in range(num_res_blocks):\n",
        "        x_g = resnet_block(x_g, filters_num)\n",
        "\n",
        "    x_g = Conv2D(filters_num, kernel_size=3, padding='same')(x_g)\n",
        "    x_g = BatchNormalization()(x_g)\n",
        "    x_g = Add()([x_1, x_g])\n",
        "\n",
        "    x_g = up_sample(x_g, filters_num * 4)\n",
        "    x_g = up_sample(x_g, filters_num * 4)\n",
        "\n",
        "    x_g = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x_g)\n",
        "    x_g = Lambda(denorm11)(x_g)\n",
        "\n",
        "    return Model(x_in, x_g)\n",
        "\n",
        "\n",
        "generator = generator_sr_resnet\n",
        "\n",
        "#Discriminator block\n",
        "def discriminator_block(x_in, filters_num, strides=1, batchnorm=True, momentum=0.8):\n",
        "    x = Conv2D(filters_num, kernel_size=3, strides=strides, padding='same')(x_in)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization(momentum=momentum)(x)\n",
        "    return LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "#Discriminator architecture\n",
        "def discriminator(filters_num=64):\n",
        "    x_in = Input(shape=(high_res_size, high_res_size, 3))\n",
        "    x_d = Lambda(norm11)(x_in)\n",
        "\n",
        "    x_d = discriminator_block(x_d, filters_num, batchnorm=False)\n",
        "    x_d = discriminator_block(x_d, filters_num, strides=2)\n",
        "\n",
        "    x_d = discriminator_block(x_d, filters_num * 2)\n",
        "    x_d = discriminator_block(x_d, filters_num * 2, strides=2)\n",
        "\n",
        "    x_d = discriminator_block(x_d, filters_num * 4)\n",
        "    x_d = discriminator_block(x_d, filters_num * 4, strides=2)\n",
        "\n",
        "    x_d = discriminator_block(x_d, filters_num * 8)\n",
        "    x_d = discriminator_block(x_d, filters_num * 8, strides=2)\n",
        "\n",
        "    x_d = Flatten()(x_d)\n",
        "\n",
        "    x_d = Dense(1024)(x_d)\n",
        "    x_d = LeakyReLU(alpha=0.2)(x_d)\n",
        "    x_d = Dense(1, activation='sigmoid')(x_d)\n",
        "\n",
        "    return Model(x_in, x_d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkNW6CGCtJsq"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xaqn3Ci44YHL"
      },
      "outputs": [],
      "source": [
        "# Train the generator\n",
        "pre_trainer = SrganGeneratorTrainer(model=generator(), checkpoint_dir=f'/content/drive/MyDrive/GenAIBOOK/SRGAN/.ckpt/pre_generator')\n",
        "pre_trainer.train(train_ds,\n",
        "                  valid_ds.take(100),\n",
        "                  steps=5000,\n",
        "                  evaluate_every=100\n",
        "                  )\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/', exist_ok=True)\n",
        "pre_trainer.model.save_weights('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/pre_generator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxQp0hIv4ayR",
        "outputId": "b9f07b7a-bb3f-4249-e220-dec1e244d1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/500, perceptual loss = 0.1516, discriminator loss = 0.9117\n",
            "400/500, perceptual loss = 0.1471, discriminator loss = 0.1896\n"
          ]
        }
      ],
      "source": [
        "gan_generator = generator() # Create Generator\n",
        "gan_generator.load_weights('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/pre_generator.h5') # loading pre trained generator\n",
        "gan_trainer = SrganTrainer(generator=gan_generator, discriminator=discriminator()) # Instantiate SR-GAN trainer\n",
        "gan_trainer.train(train_ds, steps=500) # SR GAN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLlegQRf_UIw"
      },
      "outputs": [],
      "source": [
        "# Save model weights\n",
        "gan_trainer.generator.save_weights('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/gan_generator.h5')\n",
        "gan_trainer.discriminator.save_weights('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/gan_discriminator.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5ijyM9u4p_-"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HwCchyVFt_o"
      },
      "outputs": [],
      "source": [
        "gan_generator = generator()\n",
        "#gan_generator.load_weights('/content/drive/MyDrive/GenAIBOOK/SRGAN/weights/srgan/gan_generator.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFWkDgei4uXg"
      },
      "source": [
        "#Test Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-GiO6tCF2XC"
      },
      "outputs": [],
      "source": [
        "def resolve_and_plot(lr_path):\n",
        "    lr = np.array(Image.open(lr_path))\n",
        "    gan_sr = resolve(gan_generator, tf.expand_dims(lr, axis=0))[0]\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    images = [lr, gan_sr]\n",
        "    titles = ['LR', 'SR(GAN)']\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        plt.subplot(1, 2, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(title)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo4nH7kibsI_"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir('/content/drive/MyDrive/GenAIBOOK/SRGAN/test_image/'):\n",
        "  resolve_and_plot('/content/drive/MyDrive/GenAIBOOK/SRGAN/test_image/' + file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Lk2bsdy7HtrJ"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}